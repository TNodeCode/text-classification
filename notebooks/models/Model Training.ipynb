{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2657aa0",
   "metadata": {},
   "source": [
    "# Training a Text Classification Model using the Huggingface Library\n",
    "\n",
    "In this notebook we want to train a text classification model, namely the DistilBERT model (see: https://arxiv.org/pdf/1910.01108) to classify sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from umap.umap_ import UMAP\n",
    "\n",
    "ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = load_dataset(\"emotion\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "model = AutoModel.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(model):\n",
    "    def _extract_hidden_states(batch):\n",
    "        # Place model inputs on the GPU\n",
    "        inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "        # Extract last hidden state\n",
    "        with torch.no_grad():\n",
    "            last_hidden_state = model(**inputs).last_hidden_state\n",
    "        # Return vector for CLS token\n",
    "        return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}\n",
    "    return _extract_hidden_states\n",
    "\n",
    "dataset_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "dataset_hidden = dataset_encoded.map(extract_hidden_states(model=model), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the hidden states dataset\n",
    "dataset_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4eee87",
   "metadata": {},
   "source": [
    "## Create training, validation and test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(dataset_hidden[\"train\"][\"hidden_state\"])\n",
    "y_train = np.array(dataset_hidden[\"train\"][\"label\"])\n",
    "\n",
    "X_valid = np.array(dataset_hidden[\"validation\"][\"hidden_state\"])\n",
    "y_valid = np.array(dataset_hidden[\"validation\"][\"label\"])\n",
    "\n",
    "X_test = np.array(dataset_hidden[\"test\"][\"hidden_state\"])\n",
    "y_test = np.array(dataset_hidden[\"test\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67e36a",
   "metadata": {},
   "source": [
    "## Create 2D representations of dataset tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d321e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2d_embeddings(X, y) -> pd.DataFrame:\n",
    "    # Scale features to [0, 1]\n",
    "    X_scaled = MinMaxScaler().fit_transform(X)\n",
    "    # Initialite UMAP and fit it to the data\n",
    "    mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
    "    # Create a DataFrame of 2D embeddings\n",
    "    df_emb = pd.DataFrame(mapper.embedding_, columns=[\"x1\", \"x2\"])\n",
    "    df_emb[\"label\"] = y\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ae12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2d = create_2d_embeddings(X=X_train, y=y_train)\n",
    "df_train_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b732882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_embeddings(df_2d):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12,8))\n",
    "    axes = axes.flatten()\n",
    "    cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
    "    labels = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "    for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "        df_emb_sub = df_2d.query(f\"label == {i}\")\n",
    "        axes[i].hexbin(df_emb_sub[\"x1\"], df_emb_sub[\"x2\"], cmap=cmap, gridsize=60, linewidths=(0,))\n",
    "        axes[i].set_title(label)\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "\n",
    "plot_2d_embeddings(df_2d=df_train_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67c78c",
   "metadata": {},
   "source": [
    "## Random classifier\n",
    "\n",
    "First we will look how a complete random classifier would behave. The Scikit Learn library has a classifier named DummyClassifier which can simulate such \"dumb\" models. Why should we use such a \"dumb\" classifier? To evaluate how our model behaves compared to a model that has learned nothing.\n",
    "\n",
    "There are multiple strategies a DummyClassifier can follow. We will inspect two of them:\n",
    "\n",
    "***most_frequent***: The predict method always returns the most frequent class label in the observed y argument passed to fit. This simulates a model that has collaped to predicting always the same output.\n",
    "\n",
    "***uniform***: This strategy generates predictions uniformly at random from the list of unique classes observed in y. This simulates a model that has learned nothing about the dataset.\n",
    "\n",
    "First let's train a model using the \"uniform\" strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DummyClassifier model using the 'uniform' strategy\n",
    "model_uf = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_uf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the trained model on the validation data and compute the accuracy\n",
    "model_uf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bd559",
   "metadata": {},
   "source": [
    "The DummyClassifier using the uniform strategy reaches an accuracy of 17%. So each other model that has learned something about our data should perform much better.\n",
    "\n",
    "Let's also simulate a model that has learned to always output the most frequent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b92ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DummyClassifier model using the 'most_frequent' strategy\n",
    "model_mf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_mf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the trained model on the validation data and compute the accuracy\n",
    "model_mf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40646b0",
   "metadata": {},
   "source": [
    "The \"most frequent\" strategy does not perform that good as well, but better than the uniform strategy. But also always outputting the most frequent class isn't a good behaviour of a model. Let's switch to training a real model instead of simulating dumb models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da380426",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Training\n",
    "\n",
    "First we do not train the neural network (our DistilBERT model) itself, but use its produced embeddings to train a classification model. We generate embeddings for each sentence using the pretrained model and run these embeddings through a logistic regression (LR) model from the Scikit Learn library. The LR model is trained only with the training data. After training the model we evaluate it using the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaac3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression classifier\n",
    "model_lr = LogisticRegression(max_iter=3000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the trained model on the validation data and compute the accuracy\n",
    "model_lr.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd441f",
   "metadata": {},
   "source": [
    "The accuracy is round about 63% which is not that good. It seems using the pretrained DistilBERT model does not perform well on classifying emotions with its pretrained weights, but is way better than the dumb models we explored before. It seems like the pretrained DistilBERT model already produces slightly helpful embeddings, but actually we want to score much better than 63%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a947cd",
   "metadata": {},
   "source": [
    "## Plotting a Confusion Matrix\n",
    "\n",
    "We want to explore the relaationships between the true and the predicted labels of our logistic regression model. We can do this by plotting a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=True)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "y_preds = model_lr.predict(X_valid)\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd96524",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix it looks like that joy is the most easy class to predict. The model predicts the correct label for 80% of all sentences labeled with 'joy'. The hardest classes for out model seem to be 'love' and 'joy'. The model reaches 30% or less accuracy for these classes.\n",
    "\n",
    "This is actually not a good result. it looks like the pretrained weights of the DistilBERT model are not useful for out problem. We might need to fine-tune the model to this specifiy dataset for getting better results. This is what we want to do now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred) -> dict:\n",
    "    \"\"\"This function computes accuracy and f1 score during training.\"\"\"\n",
    "    if not hasattr(pred, \"labels\"):\n",
    "        return {}\n",
    "    labels = pred.labels\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc38922",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "logging_steps = len(dataset_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"../../checkpoints/{ckpt}-finetuned-emotion\"\n",
    "train_feature_extractor = True\n",
    "\n",
    "# Instantiate a DistilBERT model with a classification head\n",
    "model_finetuned = AutoModelForSequenceClassification.from_pretrained(ckpt, num_labels=6).to(device)\n",
    "\n",
    "# Freeze parameters of transformer layers (the feature extractor) when train_feature_extractor is set to false\n",
    "if train_feature_extractor:\n",
    "    for param in model_finetuned.distilbert.parameters():\n",
    "        param.requires_grad = True\n",
    "else:\n",
    "    for param in model_finetuned.distilbert.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    "    log_level=\"error\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_finetuned,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"validation\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0edb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fc36c",
   "metadata": {},
   "source": [
    "## Evaluating the fine-tuned model\n",
    "\n",
    "Now that we have fine-tuned the model on our dataset it's time to evaluate its performance. First we will let the model generate labels for the sentences of the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(dataset_encoded[\"validation\"])\n",
    "preds_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0550142",
   "metadata": {},
   "source": [
    "## Plot the confusion matrix for the fine-tuned model\n",
    "\n",
    "Now we want to see how our fine-tuned model performs. Therefore we plot the confusion matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cff73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hidden_finetuned = dataset_encoded.map(extract_hidden_states(model=model_finetuned.distilbert.to(device)), batched=True)\n",
    "X_train_finetuned = np.array(dataset_hidden_finetuned[\"train\"][\"hidden_state\"])\n",
    "y_train_finetuned = np.array(dataset_hidden_finetuned[\"train\"][\"label\"])\n",
    "df_train_2d_finetuned = create_2d_embeddings(X=X_train_finetuned, y=y_train_finetuned)\n",
    "plot_2d_embeddings(df_2d=df_train_2d_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f7a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
